{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a15d6a",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision tree - exercise\n",
    "\n",
    "The aim of this exercise is to:\n",
    "\n",
    "* verify if a GBDT tends to overfit if the number of estimators is not\n",
    "  appropriate as previously seen for AdaBoost;\n",
    "* use the early-stopping strategy to avoid adding unnecessary trees, to\n",
    "  get the best generalization performances.\n",
    "\n",
    "We will use the California housing dataset to conduct our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c081459",
   "metadata": {},
   "source": [
    "Similarly to the previous exercise, create a gradient boosting decision tree\n",
    "and create a validation curve to assess the impact of the number of trees\n",
    "on the generalization performance of the model. Use the mean absolute error\n",
    "to assess the generalization performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import validation_curve\n",
    "# Write your code here.\n",
    "\n",
    "param_range = np.unique(np.logspace(0, 1.8, num=30)\n",
    "# Write your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846d2c3-b1d1-4f75-a497-2b3e5559aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(\n",
    "    param_range,\n",
    "    train_errors.mean(axis=1),\n",
    "    yerr=train_errors.std(axis=1),\n",
    "    label=\"Training score\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    param_range,\n",
    "    test_errors.mean(axis=1),\n",
    "    yerr=test_errors.std(axis=1),\n",
    "    label=\"Cross-validation score\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Mean absolute error in k$\\n(smaller is better)\")\n",
    "plt.xlabel(\"# estimators\")\n",
    "_ = plt.title(\"Validation curve for GBDT regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25f4ce",
   "metadata": {},
   "source": [
    "Unlike AdaBoost, the gradient boosting model will always improve when\n",
    "increasing the number of trees in the ensemble. However, it will reach a\n",
    "plateau where adding new trees will just make fitting and scoring slower.\n",
    "\n",
    "To avoid adding new unnecessary tree, gradient boosting offers an\n",
    "early-stopping option. Internally, the algorithm will use an out-of-sample\n",
    "set to compute the generalization performance of the model at each addition of a\n",
    "tree. Thus, if the generalization performance is not improving for several\n",
    "iterations, it will stop adding trees.\n",
    "\n",
    "Now, create a gradient-boosting model with `n_estimators=1000`. This number\n",
    "of trees will be too large. Change the parameter `n_iter_no_change` such\n",
    "that the gradient boosting fitting will stop after adding 5 trees that do not\n",
    "improve the overall generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
